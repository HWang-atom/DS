{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bce16e-73bc-4a9a-89b0-682a8fceaf85",
   "metadata": {},
   "source": [
    "## Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc3543-788d-4a47-9471-d237d36d7175",
   "metadata": {},
   "source": [
    "### Cleaning Walden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc60f1d-6a5a-4f7a-9f59-3c6cf5ccd232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing punctuations to remove \n",
    "remove_punc = '''!()-[]{};:'\"\\,<>/?@#$%^&*_~—“'''\n",
    "\n",
    "#Convert to lower case, remove punctuations, and write cleaned file\n",
    "with open('walden.txt', encoding='utf-8') as waldenf, open(\"walden_cleaned.txt\", \"w\", encoding='utf-8') as OUT_FILE:\n",
    "    walden = waldenf.read().lower().replace('\\n\\n', '\\n').replace('\\n',' ') #removing previous newlines  \n",
    "    walden = walden.strip().replace('. ', '.\\n') #reseperating lines after periods\n",
    "    for punc in remove_punc: \n",
    "        walden = walden.replace(punc,'')\n",
    "    OUT_FILE.write(walden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e940c66",
   "metadata": {},
   "source": [
    "Printing the first five lines for a quick view of cleaning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce19099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffthe project gutenberg ebook of walden by henry david thoreau this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with almost no restrictions whatsoever.\\n',\n",
       " 'you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org.\\n',\n",
       " 'if you are not located in the united states you will have to check the laws of the country where you are located before using this ebook.\\n',\n",
       " 'title walden author henry david thoreau release date january 1995 ebook 205 most recently updated january 28 2021 language english character set encoding utf8 produced by judith boss and david widger  start of the project gutenberg ebook walden    walden   and  on the duty of civil disobedience  by henry david thoreau  cover  contents   walden  economy  where i lived and what i lived for  reading  sounds  solitude  visitors  the beanfield  the village  the ponds  baker farm  higher laws  brute neighbors  housewarming  former inhabitants and winter visitors  winter animals  the pond in winter  spring  conclusion  on the duty of civil disobedience  walden economy when i wrote the following pages or rather the bulk of them i lived alone in the woods a mile from any neighbor in a house which i had built myself on the shore of walden pond in concord massachusetts and earned my living by the labor of my hands only.\\n',\n",
       " 'i lived there two years and two months.\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line for line in open('walden_cleaned.txt', 'r', encoding='utf8')][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e859e-06c9-4462-8512-b19bbf385d7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pairs of consecutive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0894edd-9330-4c2e-a408-cb945a6f9b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an empty filler list \n",
    "word_list = []\n",
    "#Iterate through file to generate word list\n",
    "with open('walden_cleaned.txt', encoding='utf-8') as walden:\n",
    "    for line in walden:\n",
    "        line = line.replace('.',' PERIOD ')\n",
    "        for word in line.split():\n",
    "            word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e69c42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffthe',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'of',\n",
       " 'walden',\n",
       " 'by',\n",
       " 'henry',\n",
       " 'david',\n",
       " 'thoreau']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc06df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the first element to 'the'\n",
    "word_list[0] = 'the'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac754d7b-d030-44dc-8f64-c2b8e5ade480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Zipping original word list and list with one lag together\n",
    "pair_list = list(zip(word_list[:-1], word_list[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f4e6b14-7f7a-4dca-ae86-41467850acf0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'project'),\n",
       " ('project', 'gutenberg'),\n",
       " ('gutenberg', 'ebook'),\n",
       " ('ebook', 'of'),\n",
       " ('of', 'walden'),\n",
       " ('walden', 'by'),\n",
       " ('by', 'henry'),\n",
       " ('henry', 'david'),\n",
       " ('david', 'thoreau'),\n",
       " ('thoreau', 'this')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the list \n",
    "pair_list[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb1531-044d-4d2e-9f4e-cf60d3544a5d",
   "metadata": {},
   "source": [
    "### Record frequency of word pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422c2a63-8301-4fb8-9660-860a26d753da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b74fcbdd-11b4-4319-9051-c923f8459c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate unique word list with set\n",
    "unique_word_list = list(set(word_list))\n",
    "#Decide dimensions of dataframe with length of unique words\n",
    "n = len(unique_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6143093-c780-47e2-abca-f5a39a9dcacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a dataframe with a matrix of zeros as counting base\n",
    "count_df = pd.DataFrame(np.zeros((n, n)))\n",
    "\n",
    "#Assign unique words list to be the column and row names for dataframe\n",
    "count_df.columns = unique_word_list\n",
    "count_df.index = unique_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaca9aa2-5314-4aa2-9027-ff28eaab8e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expert</th>\n",
       "      <th>systematically</th>\n",
       "      <th>front</th>\n",
       "      <th>bream</th>\n",
       "      <th>constructing</th>\n",
       "      <th>solemn</th>\n",
       "      <th>smothered</th>\n",
       "      <th>christianity</th>\n",
       "      <th>freshet</th>\n",
       "      <th>owls</th>\n",
       "      <th>...</th>\n",
       "      <th>ailment</th>\n",
       "      <th>apologies</th>\n",
       "      <th>rectitude</th>\n",
       "      <th>asiatic</th>\n",
       "      <th>medicines</th>\n",
       "      <th>birch</th>\n",
       "      <th>entertained</th>\n",
       "      <th>approaching</th>\n",
       "      <th>assumed</th>\n",
       "      <th>shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>expert</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systematically</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>front</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bream</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>constructing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birch</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertained</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approaching</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assumed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shot</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12271 rows × 12271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                expert  systematically  front  bream  constructing  solemn  \\\n",
       "expert             0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "systematically     0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "front              0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "bream              0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "constructing       0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "...                ...             ...    ...    ...           ...     ...   \n",
       "birch              0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "entertained        0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "approaching        0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "assumed            0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "shot               0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "\n",
       "                smothered  christianity  freshet  owls  ...  ailment  \\\n",
       "expert                0.0           0.0      0.0   0.0  ...      0.0   \n",
       "systematically        0.0           0.0      0.0   0.0  ...      0.0   \n",
       "front                 0.0           0.0      0.0   0.0  ...      0.0   \n",
       "bream                 0.0           0.0      0.0   0.0  ...      0.0   \n",
       "constructing          0.0           0.0      0.0   0.0  ...      0.0   \n",
       "...                   ...           ...      ...   ...  ...      ...   \n",
       "birch                 0.0           0.0      0.0   0.0  ...      0.0   \n",
       "entertained           0.0           0.0      0.0   0.0  ...      0.0   \n",
       "approaching           0.0           0.0      0.0   0.0  ...      0.0   \n",
       "assumed               0.0           0.0      0.0   0.0  ...      0.0   \n",
       "shot                  0.0           0.0      0.0   0.0  ...      0.0   \n",
       "\n",
       "                apologies  rectitude  asiatic  medicines  birch  entertained  \\\n",
       "expert                0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "systematically        0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "front                 0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "bream                 0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "constructing          0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "...                   ...        ...      ...        ...    ...          ...   \n",
       "birch                 0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "entertained           0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "approaching           0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "assumed               0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "shot                  0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "\n",
       "                approaching  assumed  shot  \n",
       "expert                  0.0      0.0   0.0  \n",
       "systematically          0.0      0.0   0.0  \n",
       "front                   0.0      0.0   0.0  \n",
       "bream                   0.0      0.0   0.0  \n",
       "constructing            0.0      0.0   0.0  \n",
       "...                     ...      ...   ...  \n",
       "birch                   0.0      0.0   0.0  \n",
       "entertained             0.0      0.0   0.0  \n",
       "approaching             0.0      0.0   0.0  \n",
       "assumed                 0.0      0.0   0.0  \n",
       "shot                    0.0      0.0   0.0  \n",
       "\n",
       "[12271 rows x 12271 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcaafa73-cdbf-4038-9e5d-80869b1e1143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Interate to record count word pairs appearance by row and column\n",
    "for (i, j) in pair_list:\n",
    "    count_df.loc[i,j] += 1   #original count + 1 for word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4827fe62-6b3e-4446-b588-741d2928a527",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expert</th>\n",
       "      <th>systematically</th>\n",
       "      <th>front</th>\n",
       "      <th>bream</th>\n",
       "      <th>constructing</th>\n",
       "      <th>solemn</th>\n",
       "      <th>smothered</th>\n",
       "      <th>christianity</th>\n",
       "      <th>freshet</th>\n",
       "      <th>owls</th>\n",
       "      <th>...</th>\n",
       "      <th>ailment</th>\n",
       "      <th>apologies</th>\n",
       "      <th>rectitude</th>\n",
       "      <th>asiatic</th>\n",
       "      <th>medicines</th>\n",
       "      <th>birch</th>\n",
       "      <th>entertained</th>\n",
       "      <th>approaching</th>\n",
       "      <th>assumed</th>\n",
       "      <th>shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>expert</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systematically</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>front</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bream</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>constructing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birch</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertained</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approaching</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assumed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shot</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12271 rows × 12271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                expert  systematically  front  bream  constructing  solemn  \\\n",
       "expert             0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "systematically     0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "front              0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "bream              0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "constructing       0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "...                ...             ...    ...    ...           ...     ...   \n",
       "birch              0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "entertained        0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "approaching        0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "assumed            0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "shot               0.0             0.0    0.0    0.0           0.0     0.0   \n",
       "\n",
       "                smothered  christianity  freshet  owls  ...  ailment  \\\n",
       "expert                0.0           0.0      0.0   0.0  ...      0.0   \n",
       "systematically        0.0           0.0      0.0   0.0  ...      0.0   \n",
       "front                 0.0           0.0      0.0   0.0  ...      0.0   \n",
       "bream                 0.0           0.0      0.0   0.0  ...      0.0   \n",
       "constructing          0.0           0.0      0.0   0.0  ...      0.0   \n",
       "...                   ...           ...      ...   ...  ...      ...   \n",
       "birch                 0.0           0.0      0.0   0.0  ...      0.0   \n",
       "entertained           0.0           0.0      0.0   0.0  ...      0.0   \n",
       "approaching           0.0           0.0      0.0   0.0  ...      0.0   \n",
       "assumed               0.0           0.0      0.0   0.0  ...      0.0   \n",
       "shot                  0.0           0.0      0.0   0.0  ...      0.0   \n",
       "\n",
       "                apologies  rectitude  asiatic  medicines  birch  entertained  \\\n",
       "expert                0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "systematically        0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "front                 0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "bream                 0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "constructing          0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "...                   ...        ...      ...        ...    ...          ...   \n",
       "birch                 0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "entertained           0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "approaching           0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "assumed               0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "shot                  0.0        0.0      0.0        0.0    0.0          0.0   \n",
       "\n",
       "                approaching  assumed  shot  \n",
       "expert                  0.0      0.0   0.0  \n",
       "systematically          0.0      0.0   0.0  \n",
       "front                   0.0      0.0   0.0  \n",
       "bream                   0.0      0.0   0.0  \n",
       "constructing            0.0      0.0   0.0  \n",
       "...                     ...      ...   ...  \n",
       "birch                   0.0      0.0   0.0  \n",
       "entertained             0.0      0.0   0.0  \n",
       "approaching             0.0      0.0   0.0  \n",
       "assumed                 0.0      0.0   0.0  \n",
       "shot                    0.0      0.0   0.0  \n",
       "\n",
       "[12271 rows x 12271 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96219b81-d335-45b8-80fc-eeb03c72202e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check counts\n",
    "count_df.loc['am', 'i']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9f4fbf-0254-421b-9ea1-11a1c4f14720",
   "metadata": {},
   "source": [
    "### Normalize counts and turn into probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f1d50a2-fac0-4edb-91e6-650f8d841370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy a new dataframe for calculating probabilities\n",
    "prob_df = count_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca0e0921-cbb4-490d-9d98-a751a476933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through rows in dataframe to get entries for each word\n",
    "for index, row in prob_df.iterrows():\n",
    "    prob_df.loc[index] = prob_df.loc[index]/sum(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b57b7dcb-a9db-4fa7-8e3c-323744dbf44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019230769230769232"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check probabilities\n",
    "prob_df.loc['am']['i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "600d8b97-8daa-4624-a0c5-c86ddc6c7031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011049723756906077"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check probabilities\n",
    "prob_df.loc['i']['lived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e3f7103-cf1c-4a13-bf48-2887dc3cbd04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Check probabilities sum\n",
    "i = 0\n",
    "for index, row in prob_df.iterrows():\n",
    "    if i <= 10: print(sum(row))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b4e9c-1fe5-4ab3-8790-142137da608f",
   "metadata": {},
   "source": [
    "### Generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f7d81",
   "metadata": {},
   "source": [
    "We pick 'the' as the starting word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a088daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Initialization for looping\n",
    "import random\n",
    "random.seed(1) #setting seed\n",
    "\n",
    "sentence_list = [] #Design the frame of output as an array\n",
    "counter = 0 #sentences counter\n",
    "number = 0 #words counter in each sentence\n",
    "prev_word = 'the' #records the previous word; we choose to start with 'the'\n",
    "\n",
    "###Looping to get sentences\n",
    "for counter in range(0,100):\n",
    "    temp_sentence = [] #record each sentence in a list\n",
    "    for number in range(0,10):\n",
    "        if prev_word == 'PERIOD':\n",
    "            prev_word = random.choices(unique_word_list, prob_df.loc[prev_word])[0] #update the word choice if met PERIOD\n",
    "            break      #break the loop and start a new sentence after PERIOD\n",
    "        temp_sentence.append(prev_word)    #adding previous word to sentence\n",
    "        prev_word = random.choices(unique_word_list, prob_df.loc[prev_word])[0] #updating previous word after each append\n",
    "        number += 1\n",
    "    if number == 0: continue #skip empty sentence which met the first word 'PERIOD'\n",
    "    sentence_list.append(' '.join(temp_sentence))  #record generated sentence as a string and save to sentence list\n",
    "    counter += 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76d3bb74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the same password repeated where a garret for your side',\n",
       " 'standing by a man or plaster',\n",
       " 'in sufficient space or four inches wide indentation in diameter',\n",
       " 'very simplicity and he appeared to pursue his employer who',\n",
       " 'would do not realize me come with tremulous sincerity truth',\n",
       " 'not allow me to sleep',\n",
       " '25 two or in the bottom where the whole extent',\n",
       " 'had for a man must first fruits” as i do',\n",
       " 'the lower in a wise man thinking of all around',\n",
       " 'it as well and tremble',\n",
       " 'before it would draw itthere being good books and i',\n",
       " 'returned too late peas for winter to be well he',\n",
       " 'had made what is broken withal far from the forum',\n",
       " 'of the country or acquiring property and idle if we',\n",
       " 'are suggestive of in and the day comes to live',\n",
       " 'aloof from texts not without illwill without feathersand that i',\n",
       " 'made most memorable ending a new england who knows not',\n",
       " 'wish to the fishes dart at the material was handed',\n",
       " 'down there the sprouts which the opposite shore half unnecessary',\n",
       " 'or elsewhere said that many wild ducks come up and',\n",
       " 'crushing loads',\n",
       " 'these are undoubtedly in winter day comes sifting down moon',\n",
       " 'i may perhaps if thy nature a bowl broken at',\n",
       " 'once giving place',\n",
       " 'let me even in which is the pond water so',\n",
       " 'pulled wool” which he seemed full project gutenbergtm trademark but',\n",
       " 'i used to me to a man to be ripe',\n",
       " 'i have learned a right angle for having come home',\n",
       " 'a mind may persuade your neighborhood',\n",
       " '9',\n",
       " 'walden vale by communication with his farm work in any',\n",
       " 'necessity have fashionable or gradually assumed their relative rank behind',\n",
       " 'dwindled into hours',\n",
       " 'on there for numbers engaged the nests and whence he',\n",
       " 'showed the fullest dinner and then be men to mill',\n",
       " 'and shepherd',\n",
       " 'there is exposed to cut my contemporaries no other clothes',\n",
       " 'are many of animals the outskirts having done as if',\n",
       " 'i should have the air while to its loose network',\n",
       " 'of it is counterbalanced this horse whose seeds which results',\n",
       " 'from the partridge conveying some of the jerbilla family',\n",
       " 'the indescribable light and eaten temperately need fear of loversand',\n",
       " 'to atmospheric changes in this age of cosmos out of',\n",
       " 'all very woods and then first be a stream there',\n",
       " 'was in siberia',\n",
       " 'quoil came running on the surface with the rules to',\n",
       " 'the wind and the idlei might gather the opponents to',\n",
       " 'individualize them there long the other kinds a double lobed',\n",
       " 'or the actions be the several heads',\n",
       " 'but the work like the little goodness somewhere for thinkers',\n",
       " 'and satisfied with consummate skill has no concern ourselves though',\n",
       " 'in addition from exertion of doors one pumpkin',\n",
       " '1',\n",
       " 'the ground since though needlessly got hold it and political',\n",
       " 'worthies either of rills are incessantly',\n",
       " 'but the lowing of the essential laws of the lightas',\n",
       " 'if we exaggerate any winter and criticism of the question',\n",
       " 'how can he was very springy soilindeed all external senses',\n",
       " '” the meaning of our heads and friendliness',\n",
       " 'as made him for his industry of the days of',\n",
       " 'a feeble intellects',\n",
       " 'if that a trowel without the character inherent in the',\n",
       " 'revelation to the surface of this electronic works provided no',\n",
       " 'polltax for he did not always and dash and as',\n",
       " 'the pond was wholly unintended',\n",
       " 'i sat there no polltax for this pond nearest the',\n",
       " 'ground early in the united states you in all our',\n",
       " 'genius which are magnified and grander tone referred to bother',\n",
       " 'honest done',\n",
       " 'such desperate city of politicians and philadelphia nearly synonymous with',\n",
       " 'the world be hindered from time to do with snow',\n",
       " 'made aware of my feet deep they suddenly disperse on',\n",
       " 'far above the shore and he comes laws and recovered',\n",
       " 'innocence we at the field of rules called on the',\n",
       " 'railroad was about the proprietors themselves',\n",
       " 'nay i think i was locked in such an hour',\n",
       " 'i am acquainted with any country but one september gale',\n",
       " 'would come over those clouds',\n",
       " 'having become one should be what mean something to many',\n",
       " 'respects and capacious bed and a spring into the common',\n",
       " 'sense',\n",
       " 'even temperament of beans are at length and so wise',\n",
       " 'speculations on a strain that the recesses of a million',\n",
       " 'households in many pailfuls of carrying on the rear avenues',\n",
       " 'and ottomans and deep and had grown perch and even',\n",
       " 'a garret and the 13th of a sigh humanely and',\n",
       " 'fairhaven pond and is so that i asked the money',\n",
       " 'spend my hoeing a day’s solitude but it was still']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac25f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output generated text\n",
    "file_generated = open('generated_walden.txt', 'w')\n",
    "for sentence in sentence_list:\n",
    "    #add line breakers after each sentence\n",
    "    sentence = sentence + '\\n'\n",
    "    file_generated.write(sentence)\n",
    "file_generated.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763d4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
